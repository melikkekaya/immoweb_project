# Immoweb Web Scraping Project

This project involved web scraping real estate data from the Immoweb website to collect information on houses and apartments. The collected data has been stored in a CSV file for further analysis and use in various applications.

## Team

This project was collaboratively developed by our team at Becode.org. The team members are:

- [Melike KAYA](https://github.com/melikkekaya)
- [Mourad Amjahed](https://github.com/Mourad-Amj)
- [Maciej Krasowski](https://github.com/maciejkrsk)
- [Nasim Ghaffarisaeidabad](https://github.com/Nafas2023)

## Project Overview

The goal of this project was to gather comprehensive data on houses and apartments listed on the Immoweb website. The collected dataset includes the following information for each property:

   - Property ID
   - Location
   - Type of property
   - Price
   - Number of rooms
   - Living area
   - Fully equipped kitchen (Yes/No)
   - Furnished (Yes/No)
   - Open fire (Yes/No)
   - Terrace (Yes/No) and its area
   - Garden (Yes/No) and its area
   - Surface of the land
   - Surface area of the plot of land
   - Number of facades
   - Swimming pool (Yes/No)
   - State of the building (New, to be renovated, etc.)

# Instructions

## Installation
To run the web scraping script, follow these steps:

- Clone this GitHub repository to your local machine.
- Install the required dependencies by running pip install -r requirements.txt.
- Ensure you have Python 3.7 or higher installed.

## Usage

Open the scrape_immoweb.py file.
Modify the script to specify your desired search criteria (e.g., location, property type, price range).
Run the script using python scrape_immoweb.py.
The script will scrape the Immoweb website based on your search criteria and collect the property data.
The collected data will be stored in a CSV file named immoweb_data.csv.

# Personal Situation
In this project, we faced various challenges and worked together to overcome them. We applied web scraping techniques to extract data from Immoweb efficiently. Additionally, we ensured the collected dataset was clean and contained accurate information.


For any inquiries or additional information, please feel free to contact us.